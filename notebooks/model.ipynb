{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "mount_file_id": "1WPx9RFD-uoikp_uzWhRvV_OolO09_ldq",
      "authorship_tag": "ABX9TyPqumuXsmO91oXjl22n4zEj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkarshminhas/violence-detection-fyp/blob/main/notebooks/model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WaXICVsuHU6"
      },
      "source": [
        "# Set dataset paths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQEVSs33txCW"
      },
      "source": [
        "raw_rwf_dir = '/content/drive/Shareddrives/Final Year Project/Datasets/Mini-RWF-2000'\r\n",
        "processed_rwf_dir = '/content/drive/Shareddrives/Final Year Project/Datasets/Processed'"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t87_UH59-lGw"
      },
      "source": [
        "# Export to frames"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z01RVcLiA9ra"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from tqdm import tqdm\r\n",
        "import numpy as np"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96SudV8E-kXu"
      },
      "source": [
        "def generate_base_folders():\r\n",
        "    if not os.path.exists(processed_rwf_dir):\r\n",
        "        os.makedirs(processed_rwf_dir)\r\n",
        "\r\n",
        "    categories = os.listdir(raw_rwf_dir)\r\n",
        "    \r\n",
        "    for category in categories:\r\n",
        "        cur_op_dir = os.path.join(processed_rwf_dir, category)\r\n",
        "        print(category, cur_op_dir)\r\n",
        "        if not os.path.exists(cur_op_dir):\r\n",
        "            os.makedirs(cur_op_dir)\r\n",
        "\r\n",
        "def convert_to_frames():\r\n",
        "    categories = os.listdir(raw_rwf_dir)\r\n",
        "\r\n",
        "    for category in categories:\r\n",
        "        videos = os.listdir(os.path.join(raw_rwf_dir, category))\r\n",
        "\r\n",
        "        for video in tqdm(videos):\r\n",
        "            generate_frames(category, video)\r\n",
        "\r\n",
        "\r\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2(\r\n",
        "        varThreshold=15,\r\n",
        "    detectShadows=True\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "def get_mask(frame):\r\n",
        "    mog_mask = fgbg.apply(frame)\r\n",
        "    median_blur_mask = cv2.medianBlur(mog_mask, 5)\r\n",
        "    bilateral_filter_mask = cv2.bilateralFilter(median_blur_mask, 9, 75, 75)\r\n",
        "    gaussian_blur_mask = cv2.GaussianBlur(bilateral_filter_mask, (13, 13), 5)\r\n",
        "\r\n",
        "    return gaussian_blur_mask\r\n",
        "\r\n",
        "\r\n",
        "def generate_frames(category, video):\r\n",
        "    base_video_name, _ = os.path.splitext(video)\r\n",
        "    video_ip_path = os.path.join(raw_rwf_dir, category, video)\r\n",
        "    video_op_dir_path = os.path.join(processed_rwf_dir, category, base_video_name)\r\n",
        "\r\n",
        "    if not os.path.exists(video_op_dir_path):\r\n",
        "        os.makedirs(video_op_dir_path)\r\n",
        "\r\n",
        "    cap = cv2.VideoCapture(video_ip_path)\r\n",
        "    framerate = int(cap.get(5))\r\n",
        "\r\n",
        "    capture_frequency = 5\r\n",
        "\r\n",
        "    while True:\r\n",
        "        frame_number = int(cap.get(1))\r\n",
        "        success, frame = cap.read()\r\n",
        "\r\n",
        "        if not success or frame is None:\r\n",
        "            break\r\n",
        "\r\n",
        "        masked_frame = get_mask(frame)\r\n",
        "\r\n",
        "        if frame_number % capture_frequency == 1:\r\n",
        "            exporting_frame_number = int(frame_number / capture_frequency)\r\n",
        "            frame_path = os.path.join(video_op_dir_path, \"frame_{0:0=3d}.jpg\".format(exporting_frame_number))\r\n",
        "            cv2.imwrite(frame_path, masked_frame )\r\n",
        "\r\n",
        "        k = cv2.waitKey(30)\r\n",
        "\r\n",
        "        if k == 27 or k == ord('q'):\r\n",
        "            break\r\n",
        "\r\n",
        "        cap.release()\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaJkyokAR8pQ"
      },
      "source": [
        "with tf.device('/device:CPU:0'):\r\n",
        "    convert_to_frames()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGgaCKJM-ssP"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1sGyGgv-uQn"
      },
      "source": [
        "# lalalal"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PjHXArg-qNm"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1b5E8sDU7f6"
      },
      "source": [
        "## Training and validation generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keaYaQdWU-G3",
        "outputId": "b6469530-66c9-46b9-961d-d7ad3a17759f"
      },
      "source": [
        "def preprocess(img):\r\n",
        "    img = cv2.resize(img, (128, 128))\r\n",
        "    img = img / 255.0\r\n",
        "    return img\r\n",
        "\r\n",
        "def get_data(batch_size):\r\n",
        "    batch = [] # N elements\r\n",
        "\r\n",
        "    label_to_int = {\r\n",
        "        'Fight': 1,\r\n",
        "        'NonFight': 0\r\n",
        "    }\r\n",
        "\r\n",
        "    categories = os.listdir(processed_rwf_dir)\r\n",
        "\r\n",
        "    for category in categories:\r\n",
        "        videos = os.listdir(os.path.join(processed_rwf_dir, category))\r\n",
        "\r\n",
        "        for video in videos:\r\n",
        "            frames = os.listdir(os.path.join(processed_rwf_dir, category, video))\r\n",
        "\r\n",
        "            current_video = []\r\n",
        "\r\n",
        "            for frame in frames:\r\n",
        "                frame_path = os.path.join(processed_rwf_dir, category, video, frame)\r\n",
        "                img = cv2.imread(frame_path)\r\n",
        "                img = preprocess(img)\r\n",
        "                current_video.append(img)\r\n",
        "\r\n",
        "                # print(img.shape, len(current_video))\r\n",
        "\r\n",
        "            current_video = np.array(current_video)\r\n",
        "            batch.append(current_video)\r\n",
        "\r\n",
        "            if len(batch) == batch_size:\r\n",
        "                batch = np.array(batch)\r\n",
        "                print(batch.shape)\r\n",
        "                yield batch\r\n",
        "                batch = []\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def data_generator():\r\n",
        "    pass\r\n",
        "\r\n",
        "cur = next(get_data(2))\r\n",
        "# print(cur.shape)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 30, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OFrBT6YwGlM",
        "outputId": "5ee4a387-d802-46a3-a75c-9b0b08166024"
      },
      "source": [
        "image_size = (128, 128)\r\n",
        "\r\n",
        "ds_train = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "    processed_rwf_dir,\r\n",
        "    labels=\"inferred\",\r\n",
        "    label_mode=\"binary\",\r\n",
        "    color_mode=\"grayscale\",\r\n",
        "    batch_size=seq_len,\r\n",
        "    image_size=image_size,\r\n",
        "    subset='training',\r\n",
        "    validation_split=0.2,\r\n",
        "    seed=1\r\n",
        ")\r\n",
        "\r\n",
        "ds_val = tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "    processed_rwf_dir,\r\n",
        "    labels=\"inferred\",\r\n",
        "    label_mode=\"binary\",\r\n",
        "    color_mode=\"grayscale\",\r\n",
        "    batch_size=seq_len,\r\n",
        "    image_size=image_size,\r\n",
        "    subset='validation',\r\n",
        "    validation_split=0.2,\r\n",
        "    seed=1\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 360 files belonging to 2 classes.\n",
            "Using 288 files for training.\n",
            "Found 360 files belonging to 2 classes.\n",
            "Using 72 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zp2CLFAy0OJJ",
        "outputId": "23c9d03a-3785-4497-8191-f3386d1095c8"
      },
      "source": [
        "print(ds_train)\r\n",
        "\r\n",
        "# for image_batch, labels_batch in ds_train:\r\n",
        "#     print(image_batch.shape)\r\n",
        "#     print(labels_batch.shape)\r\n",
        "#     break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: ((None, 128, 128, 1), (None, 1)), types: (tf.float32, tf.float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05EB_MgX1DOM"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FO1sWx851L3t"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-q4-Usr1EyH"
      },
      "source": [
        "from tensorflow.keras import layers\r\n",
        "import numpy as np\r\n",
        "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, \\\r\n",
        "Flatten, LSTM, Dropout, BatchNormalization\r\n",
        "from keras import models\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras import optimizers\r\n",
        "import tensorflow_addons as tfa"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtKbgwky1OP5"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ7GwVbU7GWl"
      },
      "source": [
        "input_shape = (seq_len, image_size[0], image_size[1], 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBjJKLNv1N3E",
        "outputId": "df75b928-a347-4cc0-aa55-bca02133f5e2"
      },
      "source": [
        "model = models.Sequential(\r\n",
        "    [\r\n",
        "        TimeDistributed(\r\n",
        "            Conv2D(64, (3, 3), activation=tf.nn.relu), \r\n",
        "            input_shape=input_shape\r\n",
        "        ),\r\n",
        "        TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))),\r\n",
        "        TimeDistributed(Conv2D(128, (4, 4), activation=tf.nn.relu)),\r\n",
        "        TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\r\n",
        "        TimeDistributed(Conv2D(256, (4, 4), activation=tf.nn.relu)),\r\n",
        "        TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\r\n",
        "        TimeDistributed(Flatten()),\r\n",
        "        Dropout(0.5),\r\n",
        "        LSTM(256, return_sequences=False, dropout=0.5),\r\n",
        "        Dense(2, activation=tf.nn.sigmoid)\r\n",
        "    ]\r\n",
        ")\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_175 (TimeDi (None, 30, 126, 126, 64)  640       \n",
            "_________________________________________________________________\n",
            "time_distributed_176 (TimeDi (None, 30, 125, 125, 64)  0         \n",
            "_________________________________________________________________\n",
            "time_distributed_177 (TimeDi (None, 30, 122, 122, 128) 131200    \n",
            "_________________________________________________________________\n",
            "time_distributed_178 (TimeDi (None, 30, 61, 61, 128)   0         \n",
            "_________________________________________________________________\n",
            "time_distributed_179 (TimeDi (None, 30, 58, 58, 256)   524544    \n",
            "_________________________________________________________________\n",
            "time_distributed_180 (TimeDi (None, 30, 29, 29, 256)   0         \n",
            "_________________________________________________________________\n",
            "time_distributed_181 (TimeDi (None, 30, 215296)        0         \n",
            "_________________________________________________________________\n",
            "dropout_25 (Dropout)         (None, 30, 215296)        0         \n",
            "_________________________________________________________________\n",
            "lstm_25 (LSTM)               (None, 256)               220726272 \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 221,383,170\n",
            "Trainable params: 221,383,170\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9imCNzga7E17"
      },
      "source": [
        "tqdm_callback = tfa.callbacks.TQDMProgressBar()\r\n",
        "model_path = 'cnn_lstm_model.h5'\r\n",
        "\r\n",
        "callbacks_list = [\r\n",
        "    tqdm_callback,\r\n",
        "    keras.callbacks.EarlyStopping(monitor=['acc'], patience=3),\r\n",
        "    keras.callbacks.ModelCheckpoint(\r\n",
        "        filepath=model_path,\r\n",
        "        monitor='val_loss',\r\n",
        "        save_best_only=True\r\n",
        "    ),\r\n",
        "    keras.callbacks.ReduceLROnPlateau(\r\n",
        "        monitor=\"val_loss\",\r\n",
        "        factor=0.1,\r\n",
        "        patience=3\r\n",
        "    )\r\n",
        "]\r\n",
        "\r\n",
        "optimizer=optimizers.RMSprop(lr=0.06)\r\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "otWXgZaD8MqK",
        "outputId": "a7439cc5-8e66-4e6b-c2ac-1a5b6fb3a714"
      },
      "source": [
        "history = model.fit(\r\n",
        "    ds_train,\r\n",
        "    validation_data=ds_val,\r\n",
        "    epochs=1,\r\n",
        "    # callbacks=callbacks_list,\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-62-848a9c966ada>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;31m# callbacks=callbacks_list,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:223 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_25 is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: (None, 128, 128, 1)\n"
          ]
        }
      ]
    }
  ]
}