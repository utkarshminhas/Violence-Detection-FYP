{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "debugger.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aBf2NctUHvIioOAZd80lHzVyFzVhJJPt",
      "authorship_tag": "ABX9TyN7hk+PLVgUd/ca5pDuzLYm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkarshminhas/violence-detection-fyp/blob/main/notebooks/working_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZjpep716eKk"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from tqdm import tqdm\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import random\r\n",
        "from glob import glob\r\n",
        "from sklearn.utils import shuffle\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmmC_QJb6qrA",
        "outputId": "5a0a24e2-1242-471e-f5cd-7f9b28fd8fb7"
      },
      "source": [
        "processed_dir = '/content/drive/Shareddrives/Datasets/Raw RWF-2000 (without_mog)'\r\n",
        "print(len(os.listdir(processed_dir)))\r\n",
        "print(len(os.listdir(processed_dir+\"/Fight\")))\r\n",
        "print(len(os.listdir(processed_dir+'/NonFight')))\r\n",
        "\r\n",
        "# image_size = (299, 299)\r\n",
        "image_size = (128, 128)\r\n",
        "nonFight, fight = (np.array(0), np.array(1))\r\n",
        "# nonFight, fight = ((None,0), (None,1))\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "1000\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epfKcG-96xbb"
      },
      "source": [
        "def load_initial_data():\r\n",
        "    x = []\r\n",
        "    y = []\r\n",
        "\r\n",
        "    # Fights\r\n",
        "    allFights = sorted(glob(os.path.join(processed_dir, 'Fight/*')))\r\n",
        "    x.extend(allFights)\r\n",
        "    y.extend([fight] * len(allFights))\r\n",
        "\r\n",
        "    # Non Fights\r\n",
        "    allNonFights = sorted(glob(os.path.join(processed_dir, 'NonFight/*')))\r\n",
        "    x.extend(allNonFights)\r\n",
        "    y.extend([nonFight] * len(allNonFights))\r\n",
        "\r\n",
        "    return x, y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUrsB1fs61FU"
      },
      "source": [
        "videoPaths, labels = load_initial_data()\r\n",
        "df = pd.DataFrame(list(zip(videoPaths, labels)), \r\n",
        "               columns =['Name', 'Label']) \r\n",
        "df=shuffle(df)\r\n",
        "# df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xrnjPvV--L_"
      },
      "source": [
        "allvideos=df.to_numpy()\r\n",
        "videos,labels=[],[]\r\n",
        "for video in allvideos:\r\n",
        "  videos.append(video[0])\r\n",
        "  labels.append(video[1])\r\n",
        "\r\n",
        "\r\n",
        "# train_videoPaths,train_labels=videos[:1500],labels[:1500]\r\n",
        "# val_videoPaths,val_labels=videos[1500:1900],labels[1500:1900]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcdbnt5XEiJt"
      },
      "source": [
        "def get_image(imagePath):\r\n",
        "    img = cv2.imread(imagePath, cv2.IMREAD_COLOR) # Read in RGB  directly\r\n",
        "    img = cv2.resize(img, image_size)\r\n",
        "    img = img / 255.0\r\n",
        "    img = img.astype(np.float32)\r\n",
        "    return img"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qit0YqxzEr_B"
      },
      "source": [
        "counter=0\r\n",
        "def preprocess(videoPath, label):\r\n",
        "    def myFunction(videoPath):\r\n",
        "        global counter\r\n",
        "        videoPath = videoPath.decode()\r\n",
        "        frames = []\r\n",
        "        for frame_path in glob(os.path.join(videoPath, '*')):\r\n",
        "            image = get_image(frame_path)\r\n",
        "            frames.append(image)\r\n",
        "        counter+=1\r\n",
        "        if counter%20==0:\r\n",
        "          print(\"\")\r\n",
        "        print(counter,end=\"->\")\r\n",
        "        return np.asarray(frames)\r\n",
        "    video = tf.numpy_function(myFunction, [videoPath], [tf.float32])[0]\r\n",
        "    # label=tf.convert_to_tensor(label)\r\n",
        "    # print(video.shape)\r\n",
        "    # label=tf.one_hot(label[0],2)\r\n",
        "    return video, label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpRKzujAEuJy"
      },
      "source": [
        "def tf_dataset(videoPaths, labels, batch_size=5):\r\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((videoPaths, labels))\r\n",
        "    dataset = dataset.map(preprocess,num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n",
        "    dataset = dataset.batch(batch_size)\r\n",
        "    dataset = dataset.cache()\r\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n",
        "    return dataset"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urJcRjROMvoo",
        "outputId": "621747e9-fa7f-48a8-e68f-8beacc758b57"
      },
      "source": [
        "ds=tf_dataset(videos[:100], labels[:100], batch_size=1)\r\n",
        "val=tf_dataset(videos[100:150], labels[100:150], batch_size=1)\r\n",
        "batched_train_dataset_len=len(ds)\r\n",
        "train_steps=batched_train_dataset_len\r\n",
        "\r\n",
        "batched_val_dataset_len=len(val)\r\n",
        "val_steps=batched_val_dataset_len\r\n",
        "\r\n",
        "print(train_steps,val_steps)\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100 50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTreJ2n1FQx8"
      },
      "source": [
        "from tensorflow.keras import layers\r\n",
        "import numpy as np\r\n",
        "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, \\\r\n",
        "Flatten, LSTM, Dropout, BatchNormalization\r\n",
        "from keras import models\r\n",
        "import itertools\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras import optimizers\r\n",
        "# import tensorflow_addons as tfa\r\n",
        "\r\n",
        "import datetime"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlXe2xw9FUj0",
        "outputId": "e4f8f2cb-4cdc-4fa9-b571-adb5f2bf6324"
      },
      "source": [
        "input_shape = (30, image_size[0], image_size[1], 3)\r\n",
        "num_epochs = 5\r\n",
        "print(input_shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeTMYX8udh2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3bbe898-b297-4e9e-d3d5-016cc5cccaac"
      },
      "source": [
        "strategy= tf.distribute.MultiWorkerMirroredStrategy()\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    model = models.Sequential(\r\n",
        "        [\r\n",
        "            TimeDistributed(\r\n",
        "                Conv2D(32, (3, 3), activation=tf.nn.relu), \r\n",
        "                input_shape=input_shape\r\n",
        "            ),\r\n",
        "            TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))),\r\n",
        "            TimeDistributed(Conv2D(32, (4, 4), activation=tf.nn.relu)),\r\n",
        "            TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\r\n",
        "            TimeDistributed(Conv2D(32, (4, 4), activation=tf.nn.relu)),\r\n",
        "            TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\r\n",
        "            TimeDistributed(Flatten()),\r\n",
        "            # Dropout(0.6),\r\n",
        "            LSTM(256, return_sequences=False, dropout=0.5,),\r\n",
        "            Dropout(0.7),\r\n",
        "            Flatten(),\r\n",
        "            Dense(64, activation=tf.nn.relu),\r\n",
        "            Dense(32, activation=tf.nn.relu),\r\n",
        "            Dense(1, activation=tf.nn.sigmoid)\r\n",
        "        ]\r\n",
        "    )\r\n",
        "\r\n",
        "    model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:CPU:0',)\n",
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CommunicationImplementation.AUTO\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, 30, 126, 126, 32)  896       \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 30, 125, 125, 32)  0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 30, 122, 122, 32)  16416     \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 30, 61, 61, 32)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 30, 58, 58, 32)    16416     \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 30, 29, 29, 32)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 30, 26912)         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               27821056  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 27,873,345\n",
            "Trainable params: 27,873,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak5ZahPsFcKt"
      },
      "source": [
        "optimizer = optimizers.Adam()\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    optimizer=optimizer,\r\n",
        "    loss=\"binary_crossentropy\",\r\n",
        "    metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXegPtBhKbKB",
        "outputId": "201beb60-84ea-4216-b0f6-aa421934dfc6"
      },
      "source": [
        "\r\n",
        "with tf.device('/device:GPU:0'):\r\n",
        "    history = model.fit(\r\n",
        "        ds,\r\n",
        "        validation_data=val,\r\n",
        "        epochs=num_epochs,\r\n",
        "        steps_per_epoch=train_steps,\r\n",
        "        validation_steps=val_steps,\r\n",
        "        batch_size=1,\r\n",
        "        validation_batch_size=1,\r\n",
        "        verbose=2,\r\n",
        "        use_multiprocessing=True,\r\n",
        "        workers=32\r\n",
        "        \r\n",
        "        \r\n",
        "    )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1->2->3->4->5->6->7->8->9->10->11->12->13->14->15->16->17->18->19->\n",
            "20->21->22->23->24->25->26->27->28->29->30->31->32->33->34->35->36->37->38->39->\n",
            "40->41->42->43->44->45->46->47->48->49->50->51->52->53->54->55->56->57->58->59->\n",
            "60->61->62->63->64->65->66->67->68->69->70->71->72->73->74->75->76->77->78->79->\n",
            "80->81->82->83->84->85->86->87->88->89->90->91->92->93->94->95->96->97->98->99->\n",
            "100->101->102->103->104->105->106->107->108->109->110->111->112->113->114->115->116->117->118->119->\n",
            "120->121->122->123->124->125->126->127->128->129->130->131->132->133->134->135->136->137->138->139->\n",
            "140->141->142->143->144->145->146->147->148->149->150->100/100 - 1088s - loss: 0.8535 - accuracy: 0.4400 - val_loss: 0.6758 - val_accuracy: 0.6600\n",
            "Epoch 2/5\n",
            "100/100 - 493s - loss: 0.7357 - accuracy: 0.5300 - val_loss: 0.6581 - val_accuracy: 0.6600\n",
            "Epoch 3/5\n",
            "100/100 - 490s - loss: 0.7591 - accuracy: 0.5300 - val_loss: 0.6858 - val_accuracy: 0.6600\n",
            "Epoch 4/5\n",
            "100/100 - 492s - loss: 0.7332 - accuracy: 0.5300 - val_loss: 0.6816 - val_accuracy: 0.6600\n",
            "Epoch 5/5\n",
            "100/100 - 490s - loss: 0.7753 - accuracy: 0.4800 - val_loss: 0.6761 - val_accuracy: 0.6600\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}