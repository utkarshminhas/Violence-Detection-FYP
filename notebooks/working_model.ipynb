{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "debugger.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aBf2NctUHvIioOAZd80lHzVyFzVhJJPt",
      "authorship_tag": "ABX9TyP9OmsqWpIitN0uD58OXpdC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkarshminhas/violence-detection-fyp/blob/main/notebooks/working_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZjpep716eKk"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from tqdm import tqdm\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import random\r\n",
        "from glob import glob\r\n",
        "from sklearn.utils import shuffle\r\n",
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmmC_QJb6qrA",
        "outputId": "f7009cc6-ea30-4c30-d7ad-177c5e1abe1b"
      },
      "source": [
        "processed_dir = '/content/drive/Shareddrives/Datasets/Raw RWF-2000 (without_mog)'\r\n",
        "print(len(os.listdir(processed_dir)))\r\n",
        "print(len(os.listdir(processed_dir+\"/Fight\")))\r\n",
        "print(len(os.listdir(processed_dir+'/NonFight')))\r\n",
        "\r\n",
        "# image_size = (299, 299)\r\n",
        "image_size = (128, 128)\r\n",
        "nonFight, fight = (np.array(0), np.array(1))\r\n",
        "# nonFight, fight = ((None,0), (None,1))\r\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "1000\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epfKcG-96xbb"
      },
      "source": [
        "def load_initial_data():\r\n",
        "    x = []\r\n",
        "    y = []\r\n",
        "\r\n",
        "    # Fights\r\n",
        "    allFights = sorted(glob(os.path.join(processed_dir, 'Fight/*')))\r\n",
        "    x.extend(allFights)\r\n",
        "    y.extend([fight] * len(allFights))\r\n",
        "\r\n",
        "    # Non Fights\r\n",
        "    allNonFights = sorted(glob(os.path.join(processed_dir, 'NonFight/*')))\r\n",
        "    x.extend(allNonFights)\r\n",
        "    y.extend([nonFight] * len(allNonFights))\r\n",
        "\r\n",
        "    return x, y"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUrsB1fs61FU"
      },
      "source": [
        "videoPaths, labels = load_initial_data()\r\n",
        "df = pd.DataFrame(list(zip(videoPaths, labels)), \r\n",
        "               columns =['Name', 'Label']) \r\n",
        "df=shuffle(df)\r\n",
        "# df"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xrnjPvV--L_"
      },
      "source": [
        "allvideos=df.to_numpy()\r\n",
        "videos,labels=[],[]\r\n",
        "for video in allvideos:\r\n",
        "  videos.append(video[0])\r\n",
        "  labels.append(video[1])\r\n",
        "\r\n",
        "\r\n",
        "# train_videoPaths,train_labels=videos[:1500],labels[:1500]\r\n",
        "# val_videoPaths,val_labels=videos[1500:1900],labels[1500:1900]"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcdbnt5XEiJt"
      },
      "source": [
        "def get_image(imagePath):\r\n",
        "    img = cv2.imread(imagePath, cv2.IMREAD_COLOR) # Read in RGB  directly\r\n",
        "    img = cv2.resize(img, image_size)\r\n",
        "    img = img / 255.0\r\n",
        "    img = img.astype(np.float32)\r\n",
        "    return img"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qit0YqxzEr_B"
      },
      "source": [
        "counter=0\r\n",
        "def preprocess(videoPath, label):\r\n",
        "    def myFunction(videoPath):\r\n",
        "        global counter\r\n",
        "        videoPath = videoPath.decode()\r\n",
        "        frames = []\r\n",
        "        for frame_path in glob(os.path.join(videoPath, '*')):\r\n",
        "            image = get_image(frame_path)\r\n",
        "            frames.append(image)\r\n",
        "        counter+=1\r\n",
        "        print(\" returning video number \", counter)\r\n",
        "        return np.asarray(frames)\r\n",
        "    video = tf.numpy_function(myFunction, [videoPath], [tf.float32])[0]\r\n",
        "    # label=tf.convert_to_tensor(label)\r\n",
        "    # print(video.shape)\r\n",
        "    # label=tf.one_hot(label[0],2)\r\n",
        "    return video, label"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpRKzujAEuJy"
      },
      "source": [
        "def tf_dataset(videoPaths, labels, batch_size=5):\r\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((videoPaths, labels))\r\n",
        "    dataset = dataset.map(preprocess,num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n",
        "    dataset = dataset.batch(batch_size)\r\n",
        "    dataset = dataset.cache()\r\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n",
        "    return dataset"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urJcRjROMvoo",
        "outputId": "0d226fab-c0d3-4fe6-c7d3-038011125101"
      },
      "source": [
        "ds=tf_dataset(videos[:100], labels[:100], batch_size=1)\r\n",
        "steps=len(ds)\r\n",
        "print(steps)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHNV4nqqEvyT"
      },
      "source": [
        "train_dataset = tf_dataset(train_videoPaths, train_labels, batch_size=1)\r\n",
        "val_dataset = tf_dataset(val_videoPaths, val_labels, batch_size=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rcsl-eSLFNYn"
      },
      "source": [
        "print(len(train_dataset))\r\n",
        "print(len(val_dataset))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ekK3tx0yJm6g"
      },
      "source": [
        "for x, y in train_dataset:\r\n",
        "    x = x.numpy()\r\n",
        "    y = y.numpy()\r\n",
        "    print(\"One Batch is:\", x.shape, y.shape)\r\n",
        "    x = x[0] \r\n",
        "    # y = y[0]\r\n",
        "    print(\"One video is:\", x.shape, y.shape, end=\"\\n\\n\")\r\n",
        "    # x = x[0] \r\n",
        "    print(\"One image is:\", x.shape, y.shape, end=\"\\n\\n\")\r\n",
        "    x *= 255\r\n",
        "    print(y)\r\n",
        "    cv2_imshow(x)\r\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRF732ZTNY_4"
      },
      "source": [
        "import tensorflow_datasets as tfds\r\n",
        "import datetime\r\n",
        "ds_numpy = tfds.as_numpy(ds)\r\n",
        "iterator = iter(ds_numpy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H0w8m8WVNruW"
      },
      "source": [
        "a = datetime.datetime.now()\r\n",
        "curr=a\r\n",
        "for x,y in iterator:\r\n",
        "  print(x.shape,y.shape)\r\n",
        "  b = datetime.datetime.now()\r\n",
        "  c = b - a\r\n",
        "  a=b\r\n",
        "  print(c.seconds)\r\n",
        "c=datetime.datetime.now()\r\n",
        "time_taken=c-curr\r\n",
        "print(time_taken.seconds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1vkzGphZN1B"
      },
      "source": [
        "# print(iterator.shape)\r\n",
        "x=next(iterator)# return a tuple of (numpy.ndarray,numpy.ndarray)\r\n",
        "print(type(x[0]),type(x[1]))\r\n",
        "\r\n",
        "print()\r\n",
        "print(x[0].shape,x[1].shape)#(2, 30, 128, 128, 3) (2,)\r\n",
        "# for ex in ds_numpy:\r\n",
        "#   # `{'image': np.array(shape=(28, 28, 1)), 'labels': np.array(shape=())}`\r\n",
        "#   print(ex[0][0].shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTreJ2n1FQx8"
      },
      "source": [
        "from tensorflow.keras import layers\r\n",
        "import numpy as np\r\n",
        "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, \\\r\n",
        "Flatten, LSTM, Dropout, BatchNormalization\r\n",
        "from keras import models\r\n",
        "import itertools\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras import optimizers\r\n",
        "# import tensorflow_addons as tfa\r\n",
        "\r\n",
        "import datetime"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlXe2xw9FUj0",
        "outputId": "3c8a110d-d660-4727-bbbc-8452295940ff"
      },
      "source": [
        "input_shape = (30, image_size[0], image_size[1], 3)\r\n",
        "num_epochs = 5\r\n",
        "print(input_shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeTMYX8udh2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82eee7b3-fccb-48ba-e0fb-34f0cfce63cc"
      },
      "source": [
        "strategy= tf.distribute.MultiWorkerMirroredStrategy()\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    model = models.Sequential(\r\n",
        "        [\r\n",
        "            TimeDistributed(\r\n",
        "                Conv2D(32, (3, 3), activation=tf.nn.relu), \r\n",
        "                input_shape=input_shape\r\n",
        "            ),\r\n",
        "            TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))),\r\n",
        "            TimeDistributed(Conv2D(32, (4, 4), activation=tf.nn.relu)),\r\n",
        "            TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\r\n",
        "            TimeDistributed(Conv2D(32, (4, 4), activation=tf.nn.relu)),\r\n",
        "            TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\r\n",
        "            TimeDistributed(Flatten()),\r\n",
        "            # Dropout(0.6),\r\n",
        "            LSTM(256, return_sequences=False, dropout=0.5,),\r\n",
        "            Dropout(0.7),\r\n",
        "            Flatten(),\r\n",
        "            Dense(64, activation=tf.nn.relu),\r\n",
        "            Dense(32, activation=tf.nn.relu),\r\n",
        "            Dense(1, activation=tf.nn.sigmoid)\r\n",
        "        ]\r\n",
        "    )\r\n",
        "\r\n",
        "    model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/device:CPU:0',)\n",
            "INFO:tensorflow:Single-worker MultiWorkerMirroredStrategy with local_devices = ('/device:CPU:0',), communication = CommunicationImplementation.AUTO\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed (TimeDistri (None, 30, 126, 126, 32)  896       \n",
            "_________________________________________________________________\n",
            "time_distributed_1 (TimeDist (None, 30, 125, 125, 32)  0         \n",
            "_________________________________________________________________\n",
            "time_distributed_2 (TimeDist (None, 30, 122, 122, 32)  16416     \n",
            "_________________________________________________________________\n",
            "time_distributed_3 (TimeDist (None, 30, 61, 61, 32)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_4 (TimeDist (None, 30, 58, 58, 32)    16416     \n",
            "_________________________________________________________________\n",
            "time_distributed_5 (TimeDist (None, 30, 29, 29, 32)    0         \n",
            "_________________________________________________________________\n",
            "time_distributed_6 (TimeDist (None, 30, 26912)         0         \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 256)               27821056  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 64)                16448     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 27,873,345\n",
            "Trainable params: 27,873,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak5ZahPsFcKt"
      },
      "source": [
        "optimizer = optimizers.Adam()\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    optimizer=optimizer,\r\n",
        "    loss=\"binary_crossentropy\",\r\n",
        "    metrics=['accuracy']\r\n",
        ")\r\n",
        "\r\n",
        "def gen():\r\n",
        "  print()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZffD8tspJM_"
      },
      "source": [
        "autotune="
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXegPtBhKbKB",
        "outputId": "a48af5a7-adad-400f-bf9f-ce59483c95c7"
      },
      "source": [
        "\r\n",
        "with tf.device('/device:GPU:0'):\r\n",
        "    history = model.fit(\r\n",
        "        ds,\r\n",
        "        # iterator,\r\n",
        "        # x=np.array(next(iterator)[0]),\r\n",
        "        # y=np.array(next(iterator)[1]),\r\n",
        "        # validation_data=val_dataset,\r\n",
        "        epochs=num_epochs,\r\n",
        "        steps_per_epoch=100,\r\n",
        "        # validation_steps=200,\r\n",
        "        batch_size=1,\r\n",
        "        # validation_batch_size=2,\r\n",
        "        verbose=2,\r\n",
        "        use_multiprocessing=True,\r\n",
        "        workers=16\r\n",
        "        \r\n",
        "        \r\n",
        "    )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            " returning video number  1\n",
            " returning video number  2\n",
            " returning video number  3\n",
            " returning video number  4\n",
            " returning video number  5\n",
            " returning video number  6\n",
            " returning video number  7\n",
            " returning video number  8\n",
            " returning video number  9\n",
            " returning video number  10\n",
            " returning video number  11\n",
            " returning video number  12\n",
            " returning video number  13\n",
            " returning video number  14\n",
            " returning video number  15\n",
            " returning video number  16\n",
            " returning video number  17\n",
            " returning video number  18\n",
            " returning video number  19\n",
            " returning video number  20\n",
            " returning video number  21\n",
            " returning video number  22\n",
            " returning video number  23\n",
            " returning video number  24\n",
            " returning video number  25\n",
            " returning video number  26\n",
            " returning video number  27\n",
            " returning video number  28\n",
            " returning video number  29\n",
            " returning video number  30\n",
            " returning video number  31\n",
            " returning video number  32\n",
            " returning video number  33\n",
            " returning video number  34\n",
            " returning video number  35\n",
            " returning video number  36\n",
            " returning video number  37\n",
            " returning video number  38\n",
            " returning video number  39\n",
            " returning video number  40\n",
            " returning video number  41\n",
            " returning video number  42\n",
            " returning video number  43\n",
            " returning video number  44\n",
            " returning video number  45\n",
            " returning video number  46\n",
            " returning video number  47\n",
            " returning video number  48\n",
            " returning video number  49\n",
            " returning video number  50\n",
            " returning video number  51\n",
            " returning video number  52\n",
            " returning video number  53\n",
            " returning video number  54\n",
            " returning video number  55\n",
            " returning video number  56\n",
            " returning video number  57\n",
            " returning video number  58\n",
            " returning video number  59\n",
            " returning video number  60\n",
            " returning video number  61\n",
            " returning video number  62\n",
            " returning video number  63\n",
            " returning video number  64\n",
            " returning video number  65\n",
            " returning video number  66\n",
            " returning video number  67\n",
            " returning video number  68\n",
            " returning video number  69\n",
            " returning video number  70\n",
            " returning video number  71\n",
            " returning video number  72\n",
            " returning video number  73\n",
            " returning video number  74\n",
            " returning video number  75\n",
            " returning video number  76\n",
            " returning video number  77\n",
            " returning video number  78\n",
            " returning video number  79\n",
            " returning video number  80\n",
            " returning video number  81\n",
            " returning video number  82\n",
            " returning video number  83\n",
            " returning video number  84\n",
            " returning video number  85\n",
            " returning video number  86\n",
            " returning video number  87\n",
            " returning video number  88\n",
            " returning video number  89\n",
            " returning video number  90\n",
            " returning video number  91\n",
            " returning video number  92\n",
            " returning video number  93\n",
            " returning video number  94\n",
            " returning video number  95\n",
            " returning video number  96\n",
            " returning video number  97\n",
            " returning video number  98\n",
            " returning video number  99\n",
            " returning video number  100\n",
            "100/100 - 766s - loss: 1.0088 - accuracy: 0.5200\n",
            "Epoch 2/5\n",
            "100/100 - 418s - loss: 0.7597 - accuracy: 0.4000\n",
            "Epoch 3/5\n",
            "100/100 - 438s - loss: 0.7748 - accuracy: 0.4500\n",
            "Epoch 4/5\n",
            "100/100 - 422s - loss: 0.7663 - accuracy: 0.4500\n",
            "Epoch 5/5\n",
            "100/100 - 420s - loss: 0.7016 - accuracy: 0.5700\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}