{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "debugger.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1aBf2NctUHvIioOAZd80lHzVyFzVhJJPt",
      "authorship_tag": "ABX9TyOpmJlUvLG1iqHv3N2dUYrP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/utkarshminhas/violence-detection-fyp/blob/main/notebooks/working_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pZjpep716eKk"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from google.colab.patches import cv2_imshow\r\n",
        "from tqdm import tqdm\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "import random\r\n",
        "from glob import glob\r\n",
        "from sklearn.utils import shuffle\r\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmmC_QJb6qrA",
        "outputId": "884983b0-fcf0-4925-83f7-b209e99452eb"
      },
      "source": [
        "processed_dir = '/content/drive/Shareddrives/Datasets/Raw RWF-2000 (without_mog)'\r\n",
        "print(len(os.listdir(processed_dir)))\r\n",
        "print(len(os.listdir(processed_dir+\"/Fight\")))\r\n",
        "print(len(os.listdir(processed_dir+'/NonFight')))\r\n",
        "\r\n",
        "# image_size = (299, 299)\r\n",
        "image_size = (128, 128)\r\n",
        "nonFight, fight = (np.array(0), np.array(1))\r\n",
        "# nonFight, fight = ((None,0), (None,1))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2\n",
            "1000\n",
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epfKcG-96xbb"
      },
      "source": [
        "def load_initial_data():\r\n",
        "    x = []\r\n",
        "    y = []\r\n",
        "\r\n",
        "    # Fights\r\n",
        "    allFights = sorted(glob(os.path.join(processed_dir, 'Fight/*')))\r\n",
        "    x.extend(allFights)\r\n",
        "    y.extend([fight] * len(allFights))\r\n",
        "\r\n",
        "    # Non Fights\r\n",
        "    allNonFights = sorted(glob(os.path.join(processed_dir, 'NonFight/*')))\r\n",
        "    x.extend(allNonFights)\r\n",
        "    y.extend([nonFight] * len(allNonFights))\r\n",
        "\r\n",
        "    return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUrsB1fs61FU"
      },
      "source": [
        "videoPaths, labels = load_initial_data()\r\n",
        "df = pd.DataFrame(list(zip(videoPaths, labels)), \r\n",
        "               columns =['Name', 'Label']) \r\n",
        "df=shuffle(df)\r\n",
        "# df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_xrnjPvV--L_"
      },
      "source": [
        "allvideos=df.to_numpy()\r\n",
        "videos,labels=[],[]\r\n",
        "for video in allvideos:\r\n",
        "  videos.append(video[0])\r\n",
        "  labels.append(video[1])\r\n",
        "\r\n",
        "\r\n",
        "# train_videoPaths,train_labels=videos[:1500],labels[:1500]\r\n",
        "# val_videoPaths,val_labels=videos[1500:1900],labels[1500:1900]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcdbnt5XEiJt"
      },
      "source": [
        "def get_image(imagePath):\r\n",
        "    img = cv2.imread(imagePath, cv2.IMREAD_COLOR) # Read in RGB  directly\r\n",
        "    img = cv2.resize(img, image_size)\r\n",
        "    img = img / 255.0\r\n",
        "    img = img.astype(np.float32)\r\n",
        "    return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qit0YqxzEr_B"
      },
      "source": [
        "counter=0\r\n",
        "def preprocess(videoPath, label):\r\n",
        "    def myFunction(videoPath):\r\n",
        "        global counter\r\n",
        "        videoPath = videoPath.decode()\r\n",
        "        frames = []\r\n",
        "        for frame_path in glob(os.path.join(videoPath, '*')):\r\n",
        "            image = get_image(frame_path)\r\n",
        "            frames.append(image)\r\n",
        "        counter+=1\r\n",
        "        if counter%50==0:\r\n",
        "            print(counter)\r\n",
        "        else:\r\n",
        "            print(counter,end=\"->\")\r\n",
        "        return np.asarray(frames)\r\n",
        "    video = tf.numpy_function(myFunction, [videoPath], [tf.float32])[0]\r\n",
        "    # label=tf.convert_to_tensor(label)\r\n",
        "    # print(video.shape)\r\n",
        "    # label=tf.one_hot(label[0],2)\r\n",
        "    return video, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpRKzujAEuJy"
      },
      "source": [
        "def tf_dataset(videoPaths, labels, batch_size=5):\r\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((videoPaths, labels))\r\n",
        "    dataset = dataset.map(preprocess,num_parallel_calls=tf.data.experimental.AUTOTUNE)\r\n",
        "    dataset = dataset.batch(batch_size)\r\n",
        "    dataset = dataset.cache()\r\n",
        "    dataset = dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\r\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urJcRjROMvoo",
        "outputId": "01fe49d5-0486-4171-e847-0bfe1fa3935d"
      },
      "source": [
        "ds=tf_dataset(videos[:10], labels[:10], batch_size=5)\r\n",
        "val=tf_dataset(videos[10:15], labels[10:15], batch_size=5)\r\n",
        "batched_train_dataset_len=len(ds)\r\n",
        "train_steps=batched_train_dataset_len\r\n",
        "\r\n",
        "batched_val_dataset_len=len(val)\r\n",
        "val_steps=batched_val_dataset_len\r\n",
        "\r\n",
        "print(train_steps,val_steps)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTreJ2n1FQx8"
      },
      "source": [
        "from tensorflow.keras import layers\r\n",
        "import numpy as np\r\n",
        "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, \\\r\n",
        "Flatten, LSTM, Dropout, BatchNormalization\r\n",
        "from keras import models\r\n",
        "import itertools\r\n",
        "\r\n",
        "import keras\r\n",
        "from keras import optimizers\r\n",
        "# import tensorflow_addons as tfa\r\n",
        "\r\n",
        "import datetime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlXe2xw9FUj0",
        "outputId": "a16138b4-5a30-4ba9-f908-b6e9d9bdb630"
      },
      "source": [
        "input_shape = (30, image_size[0], image_size[1], 3)\r\n",
        "num_epochs = 5\r\n",
        "print(input_shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 128, 128, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeTMYX8udh2c"
      },
      "source": [
        "strategy= tf.distribute.MultiWorkerMirroredStrategy()\r\n",
        "\r\n",
        "with strategy.scope():\r\n",
        "    model = models.Sequential(\r\n",
        "        [\r\n",
        "            TimeDistributed(\r\n",
        "                Conv2D(32, (3, 3), activation=tf.nn.relu), \r\n",
        "                input_shape=input_shape\r\n",
        "            ),\r\n",
        "            TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))),\r\n",
        "            TimeDistributed(Conv2D(32, (4, 4), activation=tf.nn.relu)),\r\n",
        "            TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\r\n",
        "            TimeDistributed(Conv2D(64, (4, 4), activation=tf.nn.relu)),\r\n",
        "            TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))),\r\n",
        "            TimeDistributed(Flatten()),\r\n",
        "            # Dropout(0.6),\r\n",
        "            LSTM(256, return_sequences=False, dropout=0.5,),\r\n",
        "            Dropout(0.7),\r\n",
        "            Flatten(),\r\n",
        "            Dense(64, activation=tf.nn.relu),\r\n",
        "            Dense(32, activation=tf.nn.relu),\r\n",
        "            Dense(1, activation=tf.nn.sigmoid)\r\n",
        "        ]\r\n",
        "    )\r\n",
        "\r\n",
        "    model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8pZoYL4oCga",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3b1e423-b57e-4671-ad1a-f1199aa9d691"
      },
      "source": [
        "# Load the TensorBoard notebook extension\r\n",
        "%load_ext tensorboard\r\n",
        "log_dir = \"/content/drive/Shareddrives/Datasets/Tensorboard logs\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir,)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ak5ZahPsFcKt"
      },
      "source": [
        "optimizer = optimizers.Adam()\r\n",
        "\r\n",
        "model.compile(\r\n",
        "    optimizer=optimizer,\r\n",
        "    loss=\"binary_crossentropy\",\r\n",
        "    metrics=['accuracy']\r\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lXegPtBhKbKB",
        "outputId": "a13d3668-f701-47b9-908f-174d49dffdfe"
      },
      "source": [
        "\r\n",
        "with tf.device('/device:GPU:0'):\r\n",
        "    history = model.fit(\r\n",
        "        ds,\r\n",
        "        validation_data=val,\r\n",
        "        epochs=num_epochs,\r\n",
        "        steps_per_epoch=train_steps,\r\n",
        "        validation_steps=val_steps,\r\n",
        "        # batch_size=1,\r\n",
        "        # validation_batch_size=1,\r\n",
        "        verbose=2,\r\n",
        "        use_multiprocessing=True,\r\n",
        "        workers=32,\r\n",
        "\r\n",
        "        callbacks=[tensorboard_callback]\r\n",
        "        \r\n",
        "        \r\n",
        "    )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "1->2->3->4->5->6->7->8->9->10->11->12->13->14->15->2/2 - 144s - loss: 0.7178 - accuracy: 0.5000 - val_loss: 0.7915 - val_accuracy: 0.6000\n",
            "Epoch 2/5\n",
            "2/2 - 73s - loss: 0.5742 - accuracy: 0.7000 - val_loss: 0.9376 - val_accuracy: 0.6000\n",
            "Epoch 3/5\n",
            "2/2 - 73s - loss: 0.5461 - accuracy: 0.8000 - val_loss: 0.9486 - val_accuracy: 0.6000\n",
            "Epoch 4/5\n",
            "2/2 - 73s - loss: 0.5727 - accuracy: 0.9000 - val_loss: 1.0343 - val_accuracy: 0.6000\n",
            "Epoch 5/5\n",
            "2/2 - 83s - loss: 0.8858 - accuracy: 0.7000 - val_loss: 1.0491 - val_accuracy: 0.6000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4CTSGiyRPDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f15f860b-1a88-490a-8f21-accebbcd0186"
      },
      "source": [
        "%tensorboard --logdir '/content/drive/Shareddrives/Datasets/Tensorboard logs20210225-100754'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "UsageError: Line magic function `%tensorboard` not found.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w9DHha7Lgc9B"
      },
      "source": [
        "import datetime\r\n",
        "model.save('/content/drive/Shareddrives/Final Year Project/Saved Model/' + '24Feb_2020_tfds_iter1.h5',save_format='h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}