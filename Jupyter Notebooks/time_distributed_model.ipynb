{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "using_TF_DATA",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8ZXn1JHtCEX"
      },
      "source": [
        "# -----------------------------------------------------------------STEPS------------------------------------------------------------------\r\n",
        "# convert to frames with mog\r\n",
        "# write frames to disk\r\n",
        "# make ds_train,ds_test,ds_val using tf dataset\r\n",
        "# make model\r\n",
        "# compile model\r\n",
        "# fit model\r\n",
        "# plot stats"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFfvnxBJkwqG"
      },
      "source": [
        "%tensorflow_version 2.x\r\n",
        "import tensorflow as tf\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqA1Dwh4HuQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f60ccbdf-9c07-4c7a-e2c4-5d912a0cd984"
      },
      "source": [
        "from google.colab import drive\n",
        "# drive.flush_and_unmount()\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugJmCLD6iv_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54b11754-f323-425d-90e3-a07e34cba6ec"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\r\n",
        "if device_name != '/device:GPU:0':\r\n",
        "  raise SystemError('GPU device not found')\r\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FN-OrM0lDOz"
      },
      "source": [
        "def gpu():\r\n",
        "  with tf.device('/device:GPU:0'):\r\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\r\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\r\n",
        "    return tf.math.reduce_sum(net_gpu)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ofgqo6YklHjH",
        "outputId": "0b543753-1dc7-4081-8333-67fb631776e4"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "data_dir = '/content/drive/Shareddrives/Final Year Project/Datasets/Mini-RWF-2000'\r\n",
        "!ls '$data_dir'\r\n",
        "output_dir='/content/drive/Shareddrives/Final Year Project/Datasets/Processed'\r\n",
        "\r\n",
        "if not os.path.exists(output_dir):\r\n",
        "    os.makedirs(output_dir)\r\n",
        "img_height , img_width = 128, 128\r\n",
        "seq_len = 30 # number of frames per video\r\n",
        "classes = [\"Fight\", \"NonFight\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fight  NonFight\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxeFXtiJl5Os"
      },
      "source": [
        "import os\r\n",
        "import cv2\r\n",
        "import tqdm as tqdm\r\n",
        "import tqdm.notebook as tq\r\n",
        "fgbg = cv2.createBackgroundSubtractorMOG2(\r\n",
        "    varThreshold=15,\r\n",
        "    detectShadows=True\r\n",
        ")\r\n",
        "\r\n",
        "def get_mask(frame):\r\n",
        "    mog_mask = fgbg.apply(frame)\r\n",
        "    median_blur_mask = cv2.medianBlur(mog_mask, 5)\r\n",
        "    bilateral_filter_mask = cv2.bilateralFilter(median_blur_mask, 9, 75, 75)\r\n",
        "    gaussian_blur_mask = cv2.GaussianBlur(bilateral_filter_mask, (13, 13), 5)\r\n",
        "\r\n",
        "    return gaussian_blur_mask\r\n",
        "\r\n",
        "\r\n",
        "def frames_extraction(video_path,c,filename):\r\n",
        "    frames = []\r\n",
        "    cap = cv2.VideoCapture(video_path)\r\n",
        "\r\n",
        "    frame_count = 1\r\n",
        "    selected_frames=0\r\n",
        "    print(video_path,end=\"\\n\\n\")\r\n",
        "\r\n",
        "    while True:\r\n",
        "        success, frame = cap.read()\r\n",
        "\r\n",
        "        if not success or frame is None:\r\n",
        "            break\r\n",
        "\r\n",
        "        if frame_count%5==0:\r\n",
        "          selected_frames=selected_frames+1\r\n",
        "          new_frame = get_mask(frame)\r\n",
        "          save_path=os.path.join(output_dir,c)\r\n",
        "          save_path +=\"/\"+ filename.split('.')[0] + '_frame' + str(frame_count) + '.jpg'\r\n",
        "          # print(save_path)\r\n",
        "          cv2.imwrite(save_path,new_frame)\r\n",
        "          # cv2.imshow('Novel Preprocessed Frame', new_frame)\r\n",
        "          frames.append(new_frame)\r\n",
        "\r\n",
        "        k = cv2.waitKey(30)\r\n",
        "        if selected_frames >= seq_len or k == 27 or k == ord('q'):\r\n",
        "            break\r\n",
        "\r\n",
        "        frame_count += 1\r\n",
        "\r\n",
        "    cap.release()\r\n",
        "    # cv2.destroyAllWindows()\r\n",
        "\r\n",
        "    return frames\r\n",
        "\r\n",
        "def create_data(input_dir):\r\n",
        "    X = []\r\n",
        "    Y = []\r\n",
        "     \r\n",
        "    classes_list = os.listdir(input_dir)\r\n",
        "     \r\n",
        "    for c in classes_list:\r\n",
        "        # print(c)\r\n",
        "        if not os.path.exists(output_dir):\r\n",
        "            os.makedirs(output_dir+\"\")\r\n",
        "        files_list = os.listdir(os.path.join(input_dir, c))\r\n",
        "        for f in tq.tqdm(files_list):\r\n",
        "            frames = frames_extraction(os.path.join(input_dir, c, f),c,f)\r\n",
        "           \r\n",
        "            if len(frames) == seq_len:\r\n",
        "                X.append(frames)\r\n",
        "                y = [0] * len(classes)\r\n",
        "                y[classes.index(c)] = 1\r\n",
        "                Y.append(y)\r\n",
        "     \r\n",
        "    # X = np.asarray(X)\r\n",
        "    # Y = np.asarray(Y)\r\n",
        "\r\n",
        "    # X = np.expand_dims(X, -1);\r\n",
        "    # Y = np.expand_dims(Y, -1);\r\n",
        "\r\n",
        "\r\n",
        "    return X, Y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "guoynwa2mBJl"
      },
      "source": [
        "with tf.device('/device:GPU:0'):\r\n",
        "  x,y=create_data(data_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9SxFIz8n3w6",
        "outputId": "4f50a49c-cf7c-4f09-dd3a-4e43745a2329"
      },
      "source": [
        "ds_train=tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "    '/content/drive/Shareddrives/Final Year Project/Datasets/Processed',\r\n",
        "    labels=\"inferred\",\r\n",
        "    label_mode=\"int\",\r\n",
        "    color_mode=\"rgb\",\r\n",
        "    batch_size=seq_len,\r\n",
        "    image_size=(img_height,img_width),\r\n",
        "    subset='training',\r\n",
        "    validation_split=0.2,\r\n",
        "    seed=123\r\n",
        ")\r\n",
        "ds_val=tf.keras.preprocessing.image_dataset_from_directory(\r\n",
        "    '/content/drive/Shareddrives/Final Year Project/Datasets/Processed',\r\n",
        "    labels=\"inferred\",\r\n",
        "    label_mode=\"int\",\r\n",
        "    color_mode=\"rgb\",\r\n",
        "    batch_size=seq_len,\r\n",
        "    image_size=(img_height,img_width),\r\n",
        "    subset='validation',\r\n",
        "    validation_split=0.2,\r\n",
        "    seed=123\r\n",
        ")\r\n",
        "print(\"\\nClass names: {0}\".format(ds_train.class_names))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 360 files belonging to 2 classes.\n",
            "Using 288 files for training.\n",
            "Found 360 files belonging to 2 classes.\n",
            "Using 72 files for validation.\n",
            "\n",
            "Class names: ['Fight', 'NonFight']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocHqKe12Xpaq",
        "outputId": "653d4596-5794-414c-f56c-62dc309c3f86"
      },
      "source": [
        "for image_batch, labels_batch in ds_train:\r\n",
        "  print(image_batch.shape)\r\n",
        "  print(labels_batch.shape)\r\n",
        "  break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 128, 128, 3)\n",
            "(30,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNgmP9uqZLs0",
        "outputId": "7c9bd3a0-e03f-4f4b-dc5c-9d931354f381"
      },
      "source": [
        "from tensorflow.keras import layers\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\r\n",
        "\r\n",
        "normalized_ds = ds_train.map(lambda x, y: (normalization_layer(x), y))\r\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\r\n",
        "first_image = image_batch[0]\r\n",
        "# Notice the pixels values are now in `[0,1]`.\r\n",
        "print(np.min(first_image), np.max(first_image))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0 0.9893536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sb4v1UeXJTOm"
      },
      "source": [
        "from keras.layers import TimeDistributed, Conv2D, Dense, MaxPooling2D, Flatten, LSTM, Dropout, BatchNormalization\r\n",
        "from keras import models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_FHPjQZjYTl"
      },
      "source": [
        "# --------------------------------------------copied ver 1--------------------------------------------#\r\n",
        "# model = Sequential()\r\n",
        "# model.add(TimeDistributed(Conv2D(64, 5, activation='relu', padding='same', name='conv1', input_shape=??))\r\n",
        "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', name='pool1')))\r\n",
        "\r\n",
        "# model.add(TimeDistributed(Conv2D(64, 5, activation='relu', padding='same', name='conv2'))\r\n",
        "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', name='pool2')))\r\n",
        "\r\n",
        "# model.add(TimeDistributed(Conv2D(64, 5, activation='relu', padding='same', name='conv3'))\r\n",
        "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', name='pool3')))\r\n",
        "\r\n",
        "# model.add(TimeDistributed(Conv2D(64, 5, activation='relu', padding='same', name='conv4'))\r\n",
        "# model.add(TimeDistributed(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='same', name='pool4')))\r\n",
        "\r\n",
        "\r\n",
        "# model.add(TimeDistributed(Flatten()))\r\n",
        "# model.add(LSTM(256, return_sequences=False, dropout=0.5))\r\n",
        "# model.add(Dense(1, activation='sigmoid'))\r\n",
        "\r\n",
        "# --------------------------------------------copied ver 2--------------------------------------------#\r\n",
        "\r\n",
        "model = models.Sequential()\r\n",
        "model.add(layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),)\r\n",
        "model.add(Conv2D(128, (3, 3), strides=(1,1),activation=tf.nn.relu,))\r\n",
        "model.add(Conv2D(64, (3, 3), strides=(1,1),activation=tf.nn.relu))\r\n",
        "model.add(MaxPooling2D(2,2))\r\n",
        "model.add(Conv2D(64, (3, 3), strides=(1,1),activation=tf.nn.relu))\r\n",
        "model.add(Conv2D(32, (3, 3), strides=(1,1),activation=tf.nn.relu))\r\n",
        "# model.add(MaxPooling2D(2,2))\r\n",
        "# model.add(BatchNormalization())\r\n",
        "\r\n",
        "\r\n",
        "model.add(Flatten())\r\n",
        "# model.add(Dropout(0.2))\r\n",
        "\r\n",
        "# model.add(LSTM(32,return_sequences=False,dropout=0.2)) # used 32 units   # got an error here\r\n",
        "model.add(LSTM(128))\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(64,activation=tf.nn.relu))\r\n",
        "\r\n",
        "model.add(Dropout(0.2))\r\n",
        "model.add(Dense(32,activation=tf.nn.relu))\r\n",
        "model.add(Dense(1, activation=tf.nn.sigmoid))\r\n",
        "\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6xXaiUUoaTw",
        "outputId": "85c94012-4b76-442a-a28d-edb6677e3507"
      },
      "source": [
        "model = models.Sequential()\r\n",
        "\r\n",
        "model.add(\r\n",
        "    TimeDistributed(\r\n",
        "        Conv2D(64, (3, 3), activation=tf.nn.relu), \r\n",
        "        input_shape=(seq_len, img_height,img_width, 3)\r\n",
        "    )\r\n",
        ")\r\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(1, 1))))\r\n",
        "\r\n",
        "model.add(TimeDistributed(Conv2D(128, (4,4), activation=tf.nn.relu)))\r\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\r\n",
        "\r\n",
        "model.add(TimeDistributed(Conv2D(256, (4,4), activation=tf.nn.relu)))\r\n",
        "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\r\n",
        "\r\n",
        "# extract features and dropout \r\n",
        "model.add(TimeDistributed(Flatten()))\r\n",
        "model.add(Dropout(0.5))\r\n",
        "\r\n",
        "# input to LSTM\r\n",
        "model.add(LSTM(256, return_sequences=False, dropout=0.5))\r\n",
        "\r\n",
        "# classifier with sigmoid activation for multilabel\r\n",
        "model.add(Dense(2, activation='sigmoid'))\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "time_distributed_21 (TimeDis (None, 30, 126, 126, 64)  1792      \n",
            "_________________________________________________________________\n",
            "time_distributed_22 (TimeDis (None, 30, 125, 125, 64)  0         \n",
            "_________________________________________________________________\n",
            "time_distributed_23 (TimeDis (None, 30, 122, 122, 128) 131200    \n",
            "_________________________________________________________________\n",
            "time_distributed_24 (TimeDis (None, 30, 61, 61, 128)   0         \n",
            "_________________________________________________________________\n",
            "time_distributed_25 (TimeDis (None, 30, 58, 58, 256)   524544    \n",
            "_________________________________________________________________\n",
            "time_distributed_26 (TimeDis (None, 30, 29, 29, 256)   0         \n",
            "_________________________________________________________________\n",
            "time_distributed_27 (TimeDis (None, 30, 215296)        0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 30, 215296)        0         \n",
            "_________________________________________________________________\n",
            "lstm_3 (LSTM)                (None, 256)               220726272 \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 221,384,322\n",
            "Trainable params: 221,384,322\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Rbt_HpX7tsP"
      },
      "source": [
        "import keras as keras\r\n",
        "from keras import optimizers\r\n",
        "import tensorflow_addons as tfa\r\n",
        "\r\n",
        "tqdm_callback = tfa.callbacks.TQDMProgressBar()\r\n",
        "callbacks_list=[\r\n",
        "                tqdm_callback,\r\n",
        "                keras.callbacks.EarlyStopping(monitor='acc',patience=3),\r\n",
        "                keras.callbacks.ModelCheckpoint(\r\n",
        "                    filepath='cnn_lstm_model.h5',\r\n",
        "                    monitor='val_loss',\r\n",
        "                    save_best_only=True),\r\n",
        "                keras.callbacks.ReduceLROnPlateau(monitor = \"val_loss\", factor = 0.1, patience = 3)\r\n",
        "               ]\r\n",
        "\r\n",
        "\r\n",
        "optimizer=optimizers.RMSprop(lr=0.01)\r\n",
        "model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 723
        },
        "id": "pd_Y2bJRCQYw",
        "outputId": "6dec3371-810e-41be-b4a8-c0104f037690"
      },
      "source": [
        "# Training:\r\n",
        "history=model.fit(ds_train,validation_data=ds_val,batch_size=seq_len,epochs=20,)\r\n",
        "                      #  callbacks=callbacks_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-a3c486957b65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m                       \u001b[0;31m#  callbacks=callbacks_list)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    872\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    724\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    725\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 726\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    727\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2967\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2968\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2969\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2970\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/input_spec.py:223 assert_input_compatibility\n        str(tuple(shape)))\n\n    ValueError: Input 0 of layer sequential_3 is incompatible with the layer: expected ndim=5, found ndim=4. Full shape received: (None, 128, 128, 3)\n"
          ]
        }
      ]
    }
  ]
}